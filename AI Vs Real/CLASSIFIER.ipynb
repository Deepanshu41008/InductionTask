{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c7ea4ef-a9d4-4c03-9a38-7f886bf936aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Step [0/13] Loss_D: 1.4209 Loss_G: 1.7722\n",
      "Epoch [1/50] Step [0/13] Loss_D: 0.3055 Loss_G: 4.7248\n",
      "Epoch [2/50] Step [0/13] Loss_D: 0.1030 Loss_G: 6.1856\n",
      "Epoch [3/50] Step [0/13] Loss_D: 0.0796 Loss_G: 6.9115\n",
      "Epoch [4/50] Step [0/13] Loss_D: 0.0780 Loss_G: 7.9031\n",
      "Epoch [5/50] Step [0/13] Loss_D: 0.0429 Loss_G: 7.4866\n",
      "Epoch [6/50] Step [0/13] Loss_D: 0.0813 Loss_G: 10.6766\n",
      "Epoch [7/50] Step [0/13] Loss_D: 0.0064 Loss_G: 15.2476\n",
      "Epoch [8/50] Step [0/13] Loss_D: 0.0232 Loss_G: 14.1216\n",
      "Epoch [9/50] Step [0/13] Loss_D: 0.0146 Loss_G: 10.1478\n",
      "Epoch [10/50] Step [0/13] Loss_D: 0.0222 Loss_G: 9.2741\n",
      "Epoch [11/50] Step [0/13] Loss_D: 0.0076 Loss_G: 8.8807\n",
      "Epoch [12/50] Step [0/13] Loss_D: 0.0118 Loss_G: 6.6173\n",
      "Epoch [13/50] Step [0/13] Loss_D: 0.0056 Loss_G: 11.8940\n",
      "Epoch [14/50] Step [0/13] Loss_D: 0.9055 Loss_G: 10.3035\n",
      "Epoch [15/50] Step [0/13] Loss_D: 0.2276 Loss_G: 6.4891\n",
      "Epoch [16/50] Step [0/13] Loss_D: 0.2103 Loss_G: 4.4652\n",
      "Epoch [17/50] Step [0/13] Loss_D: 0.1661 Loss_G: 4.4186\n",
      "Epoch [18/50] Step [0/13] Loss_D: 0.0985 Loss_G: 7.0243\n",
      "Epoch [19/50] Step [0/13] Loss_D: 0.0939 Loss_G: 6.2083\n",
      "Epoch [20/50] Step [0/13] Loss_D: 0.0408 Loss_G: 8.4917\n",
      "Epoch [21/50] Step [0/13] Loss_D: 0.0782 Loss_G: 5.9453\n",
      "Epoch [22/50] Step [0/13] Loss_D: 0.1143 Loss_G: 8.4357\n",
      "Epoch [23/50] Step [0/13] Loss_D: 0.0336 Loss_G: 7.8246\n",
      "Epoch [24/50] Step [0/13] Loss_D: 0.1863 Loss_G: 7.6240\n",
      "Epoch [25/50] Step [0/13] Loss_D: 0.3414 Loss_G: 6.5164\n",
      "Epoch [26/50] Step [0/13] Loss_D: 0.2306 Loss_G: 2.0810\n",
      "Epoch [27/50] Step [0/13] Loss_D: 0.6064 Loss_G: 3.4332\n",
      "Epoch [28/50] Step [0/13] Loss_D: 0.3208 Loss_G: 5.2539\n",
      "Epoch [29/50] Step [0/13] Loss_D: 0.1977 Loss_G: 4.3856\n",
      "Epoch [30/50] Step [0/13] Loss_D: 0.7661 Loss_G: 9.5151\n",
      "Epoch [31/50] Step [0/13] Loss_D: 0.2274 Loss_G: 5.0578\n",
      "Epoch [32/50] Step [0/13] Loss_D: 0.8231 Loss_G: 11.6580\n",
      "Epoch [33/50] Step [0/13] Loss_D: 0.2618 Loss_G: 4.1503\n",
      "Epoch [34/50] Step [0/13] Loss_D: 0.5070 Loss_G: 7.7532\n",
      "Epoch [35/50] Step [0/13] Loss_D: 0.1698 Loss_G: 5.3684\n",
      "Epoch [36/50] Step [0/13] Loss_D: 0.2418 Loss_G: 3.9736\n",
      "Epoch [37/50] Step [0/13] Loss_D: 0.1883 Loss_G: 4.2377\n",
      "Epoch [38/50] Step [0/13] Loss_D: 0.4202 Loss_G: 4.9762\n",
      "Epoch [39/50] Step [0/13] Loss_D: 0.1528 Loss_G: 5.3468\n",
      "Epoch [40/50] Step [0/13] Loss_D: 0.5600 Loss_G: 1.7974\n",
      "Epoch [41/50] Step [0/13] Loss_D: 0.4622 Loss_G: 4.9616\n",
      "Epoch [42/50] Step [0/13] Loss_D: 0.1869 Loss_G: 4.2882\n",
      "Epoch [43/50] Step [0/13] Loss_D: 0.1704 Loss_G: 4.3932\n",
      "Epoch [44/50] Step [0/13] Loss_D: 0.6395 Loss_G: 7.5930\n",
      "Epoch [45/50] Step [0/13] Loss_D: 0.1425 Loss_G: 4.4360\n",
      "Epoch [46/50] Step [0/13] Loss_D: 1.4762 Loss_G: 8.1674\n",
      "Epoch [47/50] Step [0/13] Loss_D: 0.3617 Loss_G: 4.3085\n",
      "Epoch [48/50] Step [0/13] Loss_D: 0.5568 Loss_G: 5.4980\n",
      "Epoch [49/50] Step [0/13] Loss_D: 0.4878 Loss_G: 3.8166\n",
      "DCGAN training complete. Models saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# DCGAN Settings\n",
    "lr = 0.0001\n",
    "beta1 = 0.5\n",
    "nz = 100  # latent vector size\n",
    "ngf = 64  # generator feature map size\n",
    "ndf = 64  # discriminator feature map size\n",
    "num_epochs = 50\n",
    "image_size = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Defined Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# 2) Defined Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "def train_dcgan(real_dir=\"RealOnly\"):\n",
    "    \"\"\"\n",
    "    This script trains DCGAN only on real images in real_dir to learn how to generate real-like images.\n",
    "    The discriminator is trained to differentiate real vs. generated images.\n",
    "    \"\"\"\n",
    "    # Created dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ])\n",
    "    real_dataset = datasets.ImageFolder(root=real_dir, transform=transform)\n",
    "    real_loader = DataLoader(real_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    netG = Generator().to(device)\n",
    "    netD = Discriminator().to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1,0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1,0.999))\n",
    "\n",
    "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, _) in enumerate(real_loader):\n",
    "            netD.zero_grad()\n",
    "            real = data.to(device)\n",
    "            b_size = real.size(0)\n",
    "            label = torch.full((b_size,), 1.0, dtype=torch.float, device=device)\n",
    "            \n",
    "            output = netD(real).view(-1)\n",
    "            errD_real = criterion(output, label)\n",
    "            errD_real.backward()\n",
    "\n",
    "            # Training with fake\n",
    "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "            fake = netG(noise)\n",
    "            label.fill_(0.0)\n",
    "            output = netD(fake.detach()).view(-1)\n",
    "            errD_fake = criterion(output, label)\n",
    "            errD_fake.backward()\n",
    "            optimizerD.step()\n",
    "\n",
    "            errD = errD_real + errD_fake\n",
    "\n",
    "            # Updating G\n",
    "            netG.zero_grad()\n",
    "            label.fill_(1.0) \n",
    "            output = netD(fake).view(-1)\n",
    "            errG = criterion(output, label)\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}] Step [{i}/{len(real_loader)}] \"\n",
    "                      f\"Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f}\")\n",
    "\n",
    "    # Save final models\n",
    "    torch.save(netG.state_dict(), \"dcgan_G.pt\")\n",
    "    torch.save(netD.state_dict(), \"dcgan_D.pt\")\n",
    "    print(\"DCGAN training complete. Models saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Provide a directory \"RealOnly/\" with subfolder e.g. \"class_for_real\" or any single label\n",
    "    # so ImageFolder can load it. All images in that folder are real.\n",
    "    train_dcgan(real_dir=r\"C:\\Users\\gupta\\Downloads\\induction-task\\Data\\Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67a00132-e9e1-4467-b48c-41ceff307009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "class DCGAN_Discriminator_Classifier(nn.Module):\n",
    "    def __init__(self, pretrained_path=None):\n",
    "        super(DCGAN_Discriminator_Classifier, self).__init__()\n",
    "        # SAME AS DISCRIMINATOR\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "    # Using a classifier layer to map out results to.\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "    #Using pretrained weights from discriminator trained earlier and extracting weights and features from it.                    \n",
    "  \n",
    "        if pretrained_path is not None:                    \n",
    "            pretrained_dict = torch.load(pretrained_path, map_location=\"cpu\")\n",
    "            own_dict = self.state_dict()\n",
    "            for k, v in pretrained_dict.items():\n",
    "                if k in own_dict and k.startswith('main.'):\n",
    "                    # example: \"main.0.weight\" in the old model => \"features.0.weight\" if indices align\n",
    "                    new_k = k.replace(\"main.\", \"features.\")\n",
    "                    own_dict[new_k] = v\n",
    "            self.load_state_dict(own_dict, strict=False)\n",
    "            print(\"Loaded partial pretrained discriminator weights (feature layers).\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_dcgan_classifier(\n",
    "    train_dir=\"Train\", \n",
    "    num_epochs=20,\n",
    "    batch_size=16,\n",
    "    lr=1e-4,\n",
    "    pretrained_d=\"dcgan_D.pt\",\n",
    "    out_model=\"dcgan_classifier.pt\"\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 2 classes: dataset.class_to_idx => { 'AI':0, 'Real':1 } (just as an example)\n",
    "    model = DCGAN_Discriminator_Classifier(pretrained_path=pretrained_d).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, (imgs, labels) in enumerate(loader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    # Saving the trained script\n",
    "    torch.save(model.state_dict(), out_model)\n",
    "    print(f\"DCGAN-based classifier saved at {out_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a72b7b65-8560-4e6b-b6da-98095059238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_dcgan_classifier(\n",
    "    model_path=\"dcgan_classifier.pt\",\n",
    "    test_dir=\"Test\",\n",
    "    output_csv=\"submission_dcgan.csv\"\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "    # Loading model\n",
    "    model = DCGAN_Discriminator_Classifier(pretrained_path=None).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Inference\n",
    "    import glob\n",
    "    from PIL import Image\n",
    "    image_paths = sorted(glob.glob(os.path.join(test_dir, \"*.*\")))\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for img_path in image_paths:\n",
    "            img_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            x = transform(img).unsqueeze(0).to(device)\n",
    "            outputs = model(x)\n",
    "            _, predicted = outputs.max(1)\n",
    "            label_str = \"AI\" if predicted.item() == 0 else \"Real\"\n",
    "            results.append([img_id, label_str])\n",
    "\n",
    "    df = pd.DataFrame(results, columns=[\"Id\",\"Label\"])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Inference complete. Saved results to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01e7e16a-648a-40d3-a69d-9c2cb042d003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_38896\\1398977366.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(pretrained_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded partial pretrained discriminator weights (feature layers).\n",
      "Epoch [1/20] Loss: 0.2535 Acc: 0.8964\n",
      "Epoch [2/20] Loss: 0.1085 Acc: 0.9638\n",
      "Epoch [3/20] Loss: 0.0844 Acc: 0.9725\n",
      "Epoch [4/20] Loss: 0.0452 Acc: 0.9875\n",
      "Epoch [5/20] Loss: 0.0394 Acc: 0.9888\n",
      "Epoch [6/20] Loss: 0.0295 Acc: 0.9925\n",
      "Epoch [7/20] Loss: 0.0279 Acc: 0.9925\n",
      "Epoch [8/20] Loss: 0.0129 Acc: 0.9988\n",
      "Epoch [9/20] Loss: 0.0112 Acc: 1.0000\n",
      "Epoch [10/20] Loss: 0.0330 Acc: 0.9900\n",
      "Epoch [11/20] Loss: 0.0196 Acc: 0.9938\n",
      "Epoch [12/20] Loss: 0.0177 Acc: 0.9938\n",
      "Epoch [13/20] Loss: 0.0076 Acc: 0.9988\n",
      "Epoch [14/20] Loss: 0.0075 Acc: 0.9988\n",
      "Epoch [15/20] Loss: 0.0112 Acc: 0.9963\n",
      "Epoch [16/20] Loss: 0.0062 Acc: 1.0000\n",
      "Epoch [17/20] Loss: 0.0095 Acc: 0.9975\n",
      "Epoch [18/20] Loss: 0.0100 Acc: 0.9975\n",
      "Epoch [19/20] Loss: 0.0091 Acc: 1.0000\n",
      "Epoch [20/20] Loss: 0.0103 Acc: 1.0000\n",
      "DCGAN-based classifier saved at dcgan_classifier.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_38896\\4008440749.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete. Saved results to submission_dcgan2.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Train DCGAN-based classifier\n",
    "    train_dcgan_classifier(\n",
    "        train_dir=r\"C:\\Users\\gupta\\Downloads\\induction-task\\Data\\Train\",     # your /AI, /Real subfolders\n",
    "        num_epochs=20,\n",
    "        batch_size=16,\n",
    "        lr=1e-4,\n",
    "        pretrained_d=\"dcgan_D.pt\",  \n",
    "        out_model=\"dcgan_classifier.pt\"\n",
    "    )\n",
    "\n",
    "    # 2) Inference\n",
    "    inference_dcgan_classifier(\n",
    "        model_path=\"dcgan_classifier.pt\",\n",
    "        test_dir=r\"C:\\Users\\gupta\\Downloads\\induction-task\\Data\\Test\",\n",
    "        output_csv=\"submission_dcgan1.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005c486-9962-4a37-bcdc-448407d18ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
